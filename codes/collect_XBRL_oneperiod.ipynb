{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the folder path\n",
    "folder_path = \"/Users/areguly6/Library/CloudStorage/OneDrive-CorvinusUniversityofBudapest/Research/XBRL/data/SEC_raw/2023q4/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the num dataset\n",
    "num_path = \"num.txt\"\n",
    "num_df = pd.read_csv(folder_path + num_path, delimiter=\"\\t\", header=0)\n",
    "\n",
    "# Read the tag dataset\n",
    "tag_path = \"tag.txt\"\n",
    "tag_df = pd.read_csv(folder_path + tag_path, delimiter=\"\\t\", header=0)\n",
    "\n",
    "# Read the sub dataset\n",
    "sub_path = \"sub.txt\"\n",
    "sub_df = pd.read_csv(folder_path + sub_path, delimiter=\"\\t\", header=0)\n",
    "\n",
    "# Read the pre dataset\n",
    "pre_path = \"pre.txt\"\n",
    "pre_df = pd.read_csv(folder_path + pre_path, delimiter=\"\\t\", header=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adsh' 'cik' 'name' 'sic' 'countryba' 'stprba' 'cityba' 'zipba' 'bas1'\n",
      " 'bas2' 'baph' 'countryma' 'stprma' 'cityma' 'zipma' 'mas1' 'mas2'\n",
      " 'countryinc' 'stprinc' 'ein' 'former' 'changed' 'afs' 'wksi' 'fye' 'form'\n",
      " 'period' 'fy' 'fp' 'filed' 'accepted' 'prevrpt' 'detail' 'instance'\n",
      " 'nciks' 'aciks']\n",
      "['tag' 'version' 'custom' 'abstract' 'datatype' 'iord' 'crdr' 'tlabel'\n",
      " 'doc']\n",
      "['adsh' 'tag' 'version' 'coreg' 'ddate' 'qtrs' 'uom' 'value' 'footnote']\n",
      "['adsh' 'report' 'line' 'stmt' 'inpth' 'rfile' 'tag' 'version' 'plabel'\n",
      " 'negating']\n"
     ]
    }
   ],
   "source": [
    "print(sub_df.columns.values)\n",
    "print(tag_df.columns.values)\n",
    "print(num_df.columns.values)\n",
    "print(pre_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign correct datatypes \n",
    "\n",
    "# SUB\n",
    "sub_df['cik'] = sub_df['cik'].astype(int)\n",
    "sub_df['sic'] = sub_df['sic'].astype('Int64')\n",
    "sub_df['ein'] = sub_df['ein'].astype(float) \n",
    "sub_df['wksi'] = sub_df['wksi'].astype('bool') \n",
    "sub_df['period'] = pd.to_datetime(sub_df['period'])\n",
    "sub_df['fy'] = sub_df['fy'].astype('Int64') \n",
    "sub_df['filed'] = pd.to_datetime(sub_df['filed'])\n",
    "sub_df['accepted'] = pd.to_datetime(sub_df['accepted'])\n",
    "sub_df['prevrpt'] = sub_df['prevrpt'].astype('bool') \n",
    "sub_df['detail'] = sub_df['detail'].astype('bool') \n",
    "sub_df['nciks'] = sub_df['nciks'].astype('Int64')\n",
    "\n",
    "# TAG\n",
    "tag_df['custom'] = tag_df['custom'].astype('bool')\n",
    "tag_df['abstract'] = tag_df['abstract'].astype('bool')\n",
    "\n",
    "# Num\n",
    "num_df['ddate'] = pd.to_datetime(num_df['ddate'])\n",
    "# num_df['coreg'] = num_df['coreg'].astype(float)\n",
    "num_df['qtrs'] = num_df['qtrs'].astype('Int64')\n",
    "num_df['value'] = num_df['value'].astype(float)\n",
    "\n",
    "# Pre\n",
    "pre_df['report'] = pre_df['report'].astype(float)\n",
    "pre_df['line'] = pre_df['line'].astype(float)\n",
    "pre_df['inpth'] = pre_df['inpth'].astype('bool')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data dimensions for merging\n",
    "\n",
    "(more here: https://www.sec.gov/files/aqfs.pdf)\n",
    "\n",
    "Notes:\n",
    "\n",
    "    - SUB: 'adsh' is the unique key. 20 char EDGAR Accession Number, with dashes in positions 11-14\n",
    "    - TAG: set of all tags used in submissions (standard and custom)\n",
    "        - unique identifier by: 'tag' (tag used by filer) and 'version; (if standard tag the taxonomy of origin, otherwise == adsh)\n",
    "    - NUM: data set of all numeric XBRL facts. unique key must be generated by combination of the following list:\n",
    "        - adsh - EDAR accession number\n",
    "        - tag - tag used by the filer\n",
    "        -version - if a standard tag, the taxonomy of origin, otherwise equal to adsh\n",
    "        - ddate - period end date\n",
    "        - qtrs - duration in number of quarters\n",
    "        - uom - unit of measure\n",
    "        - coreg - coregistrant of the parent company registrant (if applicable)\n",
    "    - PRE -- text assigned by the filer to each line item\n",
    "        - adsh\n",
    "        - report - sequential number of report within the statements\n",
    "        - line - sequential number of line within a report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match to NUM\n",
    "df = pd.merge( num_df, sub_df, how = 'left', on = 'adsh' )\n",
    "df = pd.merge( df, tag_df, how = 'left', on = ['tag','version'] )\n",
    "df = pd.merge( df, pre_df, how = 'left', on = ['adsh','tag','version'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2639066, 51)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Filters:\n",
    "\n",
    "- Company's name is stored in 'name' that is corresponds to the name of legal entity as recorded in EDGAR as of the filing date\n",
    "    - note that this may change over time!\n",
    "    - you can use: https://www.sec.gov/edgar/searchedgar/companysearch to search for company/person by name, ticker symbol or CIK\n",
    "    - you can find archives and text format CIK-company names here: https://www.sec.gov/Archives/edgar/cik-lookup-data.txt\n",
    "- Get yearly reports: 'form' == '10-K' | form == '10-K/A' leads to have 10Ks:\n",
    "    ``` \n",
    "    df = df.loc[\n",
    "    (df['form'] == '10-K') |\n",
    "    (df['form'] == '10-K/A') ]\n",
    "    ```\n",
    "- Reported accounting method - US-GAAP: 'version' == 'us-gaap'\n",
    "    ```\n",
    "    df = df.loc[ df['version'] == 'us-gaap' ] \n",
    "    ```\n",
    "- Report is done by the company itself: 'coreg' == NA (or missing, use '.isna()' ) \n",
    "    ```\n",
    "    df = df.loc[ df['coreg'].isna() ] \n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful variables:\n",
    "\n",
    "- 'ticker' that stands for the stock-exchange ticker: \n",
    "    ```\n",
    "    df.['ticker'] = df['instance'].astype(str).str.split('-', expand=True)[0].str.upper()\n",
    "    ```\n",
    "        - note however, it is 'noisy' meaning many cases missleading. \n",
    "        - To get a full picture, use instead: https://www.sec.gov/include/ticker.txt and merge with data\n",
    "- sectors can be identified by 'sic' value.\n",
    "    - Fama-French classifications -- 12 for rough 48 for detailled (e.g. banks), 30 is generally ok for analysis\n",
    "        - 48 classification: https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/Data_Library/det_48_ind_port.html\n",
    "        - 12 classification: https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/Data_Library/det_12_ind_port.html\n",
    "        - 30 classification: https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/Data_Library/det_30_ind_port.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further data\n",
    "\n",
    "- Yahho finance: https://finance.yahoo.com/\n",
    "    - can download stock prices -> stock returns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
